"""
PPO LSTM Training Script with Feature Category Combinations

This script imports the complete PPO LSTM architecture from train_ppo_lstm.py
and allows training with different combinations of feature categories:
- OHLCV (basic price data)
- Technical Indicators (volatility, momentum, moving averages, etc.)
- Financial Indicators (financial statements, ratios)
- Sentiment Indicators (news + social media sentiment)

Usage:
    python train_ppo_feature_combinations.py --feature_combination ohlcv+technical
    python train_ppo_feature_combinations.py --feature_combination all
    python train_ppo_feature_combinations.py --feature_combination ohlcv+financial+sentiment

Author: AI Assistant
Date: 2024
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from typing import Dict, List, Any, Set
import jax
import jax.numpy as jnp
import numpy as np
import pandas as pd
from functools import partial

# Import the complete PPO LSTM architecture
from train_ppo_lstm import PPOTrainer, ActorCriticLSTM, LSTMState, Trajectory
from finagent.environment.portfolio_env import JAXVectorizedPortfolioEnv, EnvState

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FeatureSelector:
    """Feature selector for different feature categories"""
    
    def __init__(self):
        # Define feature categories based on actual CSV data and portfolio_env.py analysis
        self.feature_categories = {
            'ohlcv': {
                'description': 'Basic OHLCV price data and returns',
                'features': [
                    # Basic OHLCV
                    'open', 'high', 'low', 'close', 'volume', 'vwap',
                    
                    # Returns (will be generated by engineer_features)
                    'returns_1d', 'returns_3d', 'returns_5d', 'returns_10d', 'returns_20d',
                    'log_returns_1d', 'log_returns_5d',
                    
                    # Price action features (will be generated)
                    'overnight_gap', 'daily_range', 'close_position',
                    
                    # Lag features (pre-computed in CSV)
                    'open_lag_1', 'open_lag_2', 'open_lag_3', 'open_lag_5', 'open_lag_10', 'open_lag_20',
                    'high_lag_1', 'high_lag_2', 'high_lag_3', 'high_lag_5', 'high_lag_10', 'high_lag_20',
                    'low_lag_1', 'low_lag_2', 'low_lag_3', 'low_lag_5', 'low_lag_10', 'low_lag_20',
                    'close_lag_1', 'close_lag_2', 'close_lag_3', 'close_lag_5', 'close_lag_10', 'close_lag_20',
                    'volume_lag_1', 'volume_lag_2', 'volume_lag_3', 'volume_lag_5', 'volume_lag_10', 'volume_lag_20',
                    
                    # Rolling statistics (pre-computed in CSV)
                    'open_rolling_mean_5', 'open_rolling_mean_20', 'open_rolling_std_20',
                    'high_rolling_mean_5', 'high_rolling_mean_20', 'high_rolling_std_20',
                    'low_rolling_mean_5', 'low_rolling_mean_20', 'low_rolling_std_20',
                    'close_rolling_mean_5', 'close_rolling_mean_20', 'close_rolling_std_20',
                    'close_momentum_5', 'close_momentum_20',
                    'volume_rolling_mean_5', 'volume_rolling_mean_20', 'volume_rolling_std_20'
                ]
            },
            
            'technical': {
                'description': 'Technical indicators and algorithmic trading signals',
                'features': [
                    # Moving averages (pre-computed in CSV)
                    'dma_50', 'dma_200',
                    'dma_50_lag_1', 'dma_50_lag_2', 'dma_50_lag_3', 'dma_50_lag_5', 'dma_50_lag_10', 'dma_50_lag_20',
                    'dma_200_lag_1', 'dma_200_lag_2', 'dma_200_lag_3', 'dma_200_lag_5', 'dma_200_lag_10', 'dma_200_lag_20',
                    'dma_50_rolling_mean_5', 'dma_50_rolling_mean_20', 'dma_50_rolling_std_20',
                    'dma_200_rolling_mean_5', 'dma_200_rolling_mean_20', 'dma_200_rolling_std_20',
                    'dma_cross', 'dma_distance', 'volume_price_trend',
                    
                    # RSI (pre-computed in CSV)
                    'rsi_14',
                    
                    # Volatility features (will be generated by engineer_features)
                    'volatility_5d', 'volatility_10d', 'volatility_20d', 'volatility_30d', 'volatility_60d',
                    'vol_ratio_short_long', 'vol_ratio_5_20',
                    
                    # Momentum features (will be generated)
                    'momentum_5d', 'momentum_10d', 'momentum_20d', 'momentum_60d',
                    'momentum_acceleration_10d',
                    
                    # Moving average features (will be generated)
                    'ma_convergence', 'ma_trend_strength', 'price_position_20d', 
                    'price_above_ma50', 'price_above_ma200',
                    
                    # RSI signals (will be generated)
                    'rsi_oversold', 'rsi_overbought', 'rsi_bullish_divergence', 'rsi_bearish_divergence',
                    'rsi_zscore_20d',
                    
                    # Bollinger Bands (will be generated)
                    'bb_position', 'bb_squeeze', 'bb_breakout_up', 'bb_breakout_down',
                    
                    # Mean reversion signals (will be generated)
                    'price_zscore_20d', 'price_zscore_60d', 'volume_zscore_20d', 'volume_zscore_60d',
                    'price_deviation_50d', 'price_deviation_200d',
                    'mean_reversion_signal_50d', 'mean_reversion_signal_200d',
                    
                    # Breakout signals (will be generated)
                    'price_breakout_20d', 'price_breakdown_20d', 'volume_breakout_20d', 'volume_spike',
                    
                    # Trend following (will be generated)
                    'ma_cross_bullish', 'ma_cross_bearish',
                    
                    # Volatility regime (will be generated)
                    'high_vol_regime', 'low_vol_regime', 'vol_expansion', 'vol_contraction',
                    
                    # Candlestick patterns (will be generated)
                    'body_ratio', 'upper_wick_ratio', 'lower_wick_ratio',
                    'doji_pattern', 'hammer_pattern', 'shooting_star_pattern',
                    
                    # Volume analysis (will be generated)
                    'volume_price_momentum', 'volume_ratio_5d', 'volume_ratio_20d',
                    'volume_trend_10d', 'volume_confirms_price', 'volume_divergence',
                    
                    # Signal aggregation (will be generated)
                    'bullish_signals', 'bearish_signals', 'net_signal_strength',
                    
                    # Risk-adjusted metrics (will be generated)
                    'risk_adjusted_momentum', 'volume_confirmed_trend',
                    
                    # Regime detection (will be generated)
                    'vol_regime_change', 'trend_regime',
                    
                    # Cross-sectional features (will be generated)
                    'momentum_rank_proxy', 'vol_rank_proxy'
                ]
            },
            
            'financial': {
                'description': 'Financial statement metrics and fundamental analysis',
                'features': [
                    # Core Income Statement Features (from CSV)
                    'metric_Revenue', 'metric_TotalRevenue', 'metric_CostofRevenueTotal', 'metric_GrossProfit',
                    'metric_OperatingIncome', 'metric_NetIncomeBeforeTaxes', 'metric_NetIncomeAfterTaxes',
                    'metric_NetIncome', 'metric_DilutedNetIncome', 'metric_DilutedWeightedAverageShares',
                    'metric_DilutedEPSExcludingExtraOrdItems', 'metric_DPS-CommonStockPrimaryIssue',
                    
                    # Core Balance Sheet Features (from CSV)
                    'metric_Cash', 'metric_ShortTermInvestments', 'metric_CashandShortTermInvestments',
                    'metric_TotalCurrentAssets', 'metric_TotalAssets', 'metric_TotalCurrentLiabilities',
                    'metric_TotalLiabilities', 'metric_TotalEquity', 'metric_TotalCommonSharesOutstanding',
                    
                    # Core Cash Flow Features (from CSV)
                    'metric_CashfromOperatingActivities', 'metric_CapitalExpenditures', 
                    'metric_CashfromInvestingActivities', 'metric_CashfromFinancingActivities',
                    'metric_NetChangeinCash', 'metric_TotalCashDividendsPaid',
                    
                    # Key Financial Metrics (from CSV)
                    'metric_freeCashFlowtrailing12Month', 'metric_freeCashFlowMostRecentFiscalYear',
                    'metric_periodLength', 'metric_periodType',
                    
                    # Additional financial metrics (from CSV)
                    'metric_pPerEExcludingExtraordinaryItemsMostRecentFiscalYear',
                    'metric_currentDividendYieldCommonStockPrimaryIssueLTM',
                    'metric_priceToBookMostRecentFiscalYear',
                    'metric_priceToFreeCashFlowPerShareTrailing12Months',
                    'metric_pPerEBasicExcludingExtraordinaryItemsTTM',
                    'metric_pPerEIncludingExtraordinaryItemsTTM',
                    'metric_returnOnAverageEquityMostRecentFiscalYear',
                    'metric_returnOnInvestmentMostRecentFiscalYear',
                    'metric_netProfitMarginPercentTrailing12Month',
                    'metric_operatingMarginTrailing12Month',
                    'metric_grossMarginTrailing12Month',
                    'metric_currentRatioMostRecentFiscalYear',
                    'metric_quickRatioMostRecentFiscalYear',
                    'metric_totalDebtPerTotalEquityMostRecentFiscalYear',
                    'metric_netInterestCoverageMostRecentFiscalYear',
                    'metric_marketCap',
                    'metric_beta'
                ]
            },
            
            'sentiment': {
                'description': 'News and social media sentiment indicators',
                'features': [
                    # Reddit sentiment features (from CSV)
                    'reddit_title_sentiments_mean', 'reddit_title_sentiments_std',
                    'reddit_body_sentiments', 'reddit_body_sentiments_std',
                    'reddit_score_mean', 'reddit_score_sum', 'reddit_posts_count', 'reddit_comments_sum',
                    
                    # News sentiment features (from CSV)
                    'news_sentiment_mean', 'news_articles_count', 'news_sentiment_std', 'news_sources',
                    
                    # Sentiment features that will be generated by engineer_features
                    'sentiment_momentum_3d', 'sentiment_momentum_5d',
                    'sentiment_extreme_positive', 'sentiment_extreme_negative'
                ]
            }
        }
    
    def get_features_for_combination(self, combination: str) -> List[str]:
        """
        Get list of features for a given combination string.
        
        Args:
            combination: Feature combination string like 'ohlcv+technical' or 'all'
            
        Returns:
            List of feature names
        """
        if combination.lower() == 'all':
            # Return all features from all categories
            all_features = []
            for category_features in self.feature_categories.values():
                all_features.extend(category_features['features'])
            return list(set(all_features))  # Remove duplicates
        
        # Parse combination string
        categories = [cat.strip().lower() for cat in combination.split('+')]
        
        # Validate categories
        valid_categories = set(self.feature_categories.keys())
        invalid_categories = set(categories) - valid_categories
        if invalid_categories:
            raise ValueError(f"Invalid feature categories: {invalid_categories}. "
                           f"Valid categories are: {list(valid_categories)}")
        
        # Combine features from selected categories
        selected_features = []
        for category in categories:
            selected_features.extend(self.feature_categories[category]['features'])
        
        # Remove duplicates and ensure 'close' is always first
        selected_features = list(set(selected_features))
        if 'close' in selected_features:
            selected_features.remove('close')
            selected_features = ['close'] + selected_features
        
        return selected_features
    
    def print_available_combinations(self):
        """Print available feature combinations"""
        print("\n=== Available Feature Categories ===")
        for category, info in self.feature_categories.items():
            print(f"\n{category.upper()}: {info['description']}")
            print(f"  Features ({len(info['features'])}): {', '.join(info['features'][:5])}...")
        
        print(f"\n=== Example Combinations ===")
        print("• ohlcv - Basic price data only")
        print("• technical - Technical indicators only")
        print("• financial - Financial metrics only")
        print("• sentiment - Sentiment data only")
        print("• ohlcv+technical - Price data + technical indicators")
        print("• ohlcv+financial - Price data + financial metrics")
        print("• ohlcv+sentiment - Price data + sentiment")
        print("• technical+financial - Technical + financial indicators")
        print("• technical+sentiment - Technical + sentiment indicators")
        print("• financial+sentiment - Financial + sentiment indicators")
        print("• ohlcv+technical+financial - Price + technical + financial")
        print("• ohlcv+technical+sentiment - Price + technical + sentiment")
        print("• ohlcv+financial+sentiment - Price + financial + sentiment")
        print("• technical+financial+sentiment - All except basic price data")
        print("• all - All available features")


class CustomPortfolioEnv(JAXVectorizedPortfolioEnv):
    """Custom portfolio environment with feature selection capability"""
    
    def __init__(self, selected_features: List[str], **kwargs):
        """
        Initialize environment with selected features only.
        
        Args:
            selected_features: List of features to use for training
            **kwargs: Other environment arguments
        """
        # Store selected features
        self.selected_features = selected_features
        logger.info(f"Initializing environment with {len(selected_features)} selected features")
        logger.info(f"Selected features: {selected_features[:10]}..." if len(selected_features) > 10 else f"Selected features: {selected_features}")
        
        # Initialize parent class
        super().__init__(**kwargs)
        
        # Override features in data loader
        self.data_loader.features = selected_features
        
        # Recalculate observation dimension based on selected features
        self._recalculate_observation_dim()
    
    def _recalculate_observation_dim(self):
        """Recalculate observation dimension based on selected features"""
        self.n_features = len(self.selected_features)
        
        # Updated observation size calculation
        obs_size = (
            (self.window_size * self.n_stocks * self.n_features) +  # Historical features
            self.n_stocks * 2 +                                     # Current open prices + gaps
            self.action_dim +                                       # Portfolio weights
            self.n_stocks +                                         # Short position flags
            8                                                       # Market state (8 elements)
        )
        
        self.obs_dim = obs_size
        
        logger.info(f"Recalculated observation dimension: {self.obs_dim}")
        logger.info(f"Features per stock: {self.n_features}")
        logger.info(f"Historical window features: {self.window_size * self.n_stocks * self.n_features}")
    
    def engineer_features(self, df: pd.DataFrame, stock: str) -> pd.DataFrame:
        """
        Override feature engineering to only include selected features.
        This is a simplified version that focuses on the selected features.
        """
        # Get the original feature engineering from parent
        df_engineered = super().engineer_features(df, stock)
        
        # Filter to only selected features
        available_features = [f for f in self.selected_features if f in df_engineered.columns]
        
        # Create filtered dataframe with only selected features
        filtered_df = df_engineered[available_features].copy()
        
        # Ensure 'close' is always first
        if 'close' in filtered_df.columns:
            cols = ['close'] + [c for c in filtered_df.columns if c != 'close']
            filtered_df = filtered_df[cols]
        
        return filtered_df.fillna(0.0)


class FeatureCombinationPPOTrainer(PPOTrainer):
    """PPO Trainer with feature combination support"""
    
    def __init__(self, config: Dict[str, Any], selected_features: List[str]):
        """
        Initialize trainer with selected features.
        
        Args:
            config: Training configuration
            selected_features: List of features to use
        """
        self.selected_features = selected_features
        
        # Update config to use custom environment
        config['use_custom_env'] = True
        config['selected_features'] = selected_features
        
        logger.info(f"Initializing PPO Trainer with {len(selected_features)} features")
        
        # Initialize parent class
        super().__init__(config)
    
    def _get_env_config(self) -> Dict[str, Any]:
        """Get environment configuration with feature selection"""
        base_config = super()._get_env_config()
        base_config['selected_features'] = self.selected_features
        return base_config
    
    def _initialize_environment(self):
        """Initialize custom environment with feature selection"""
        try:
            env_config = self._get_env_config()
            selected_features = env_config.pop('selected_features')
            
            # Use custom environment class
            self.env = CustomPortfolioEnv(selected_features, **env_config)
            logger.info(f"Custom environment initialized: obs_dim={self.env.obs_dim}, action_dim={self.env.action_dim}")
            logger.info(f"Using {len(selected_features)} features: {selected_features[:5]}...")
            
        except Exception as e:
            logger.error(f"Failed to initialize custom environment: {e}")
            raise


def run_training_with_combination(feature_combination: str, config: Dict[str, Any]):
    """
    Run training with a specific feature combination.
    
    Args:
        feature_combination: Feature combination string
        config: Training configuration
    """
    logger.info(f"Starting training with feature combination: {feature_combination}")
    
    # Initialize feature selector
    feature_selector = FeatureSelector()
    
    # Get selected features
    try:
        selected_features = feature_selector.get_features_for_combination(feature_combination)
        logger.info(f"Selected {len(selected_features)} features for training")
        
        # Log feature distribution by category
        for category, info in feature_selector.feature_categories.items():
            category_features = [f for f in selected_features if f in info['features']]
            logger.info(f"  {category}: {len(category_features)} features")
            
    except Exception as e:
        logger.error(f"Failed to get features for combination '{feature_combination}': {e}")
        feature_selector.print_available_combinations()
        raise
    
    # Update config with feature combination info
    config['feature_combination'] = feature_combination
    config['selected_features'] = selected_features
    config['model_name'] = f"ppo_lstm_{feature_combination.replace('+', '_')}"
    
    # Initialize trainer
    try:
        trainer = FeatureCombinationPPOTrainer(config, selected_features)
        logger.info("Feature combination PPO trainer initialized successfully")
        
    except Exception as e:
        logger.error(f"Failed to initialize trainer: {e}")
        raise
    
    # Run training
    try:
        logger.info("Starting training...")
        trainer.train()
        logger.info("Training completed successfully!")
        
        # Save final model
        trainer.save_model(f"final_model_{feature_combination.replace('+', '_')}")
        
    except Exception as e:
        logger.error(f"Training failed: {e}")
        raise


def main():
    """Main function with command line argument parsing"""
    parser = argparse.ArgumentParser(
        description="Train PPO LSTM with different feature combinations",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python train_ppo_feature_combinations.py --feature_combination ohlcv+technical
  python train_ppo_feature_combinations.py --feature_combination all --num_updates 500
  python train_ppo_feature_combinations.py --feature_combination ohlcv+financial+sentiment --use_wandb
        """
    )
    
    # Feature combination argument
    parser.add_argument(
        '--feature_combination', 
        type=str, 
        default='ohlcv+technical',
        help='Feature combination to use (e.g., ohlcv+technical, all, etc.)'
    )
    
    # Training configuration arguments
    parser.add_argument('--num_updates', type=int, default=1000, help='Number of training updates')
    parser.add_argument('--learning_rate', type=float, default=3e-4, help='Learning rate')
    parser.add_argument('--n_envs', type=int, default=8, help='Number of parallel environments')
    parser.add_argument('--n_steps', type=int, default=32, help='Number of steps per environment')
    parser.add_argument('--ppo_epochs', type=int, default=4, help='PPO epochs per update')
    parser.add_argument('--ppo_batch_size', type=int, default=128, help='PPO batch size')
    parser.add_argument('--hidden_size', type=int, default=256, help='LSTM hidden size')
    parser.add_argument('--n_lstm_layers', type=int, default=2, help='Number of LSTM layers')
    
    # Data configuration arguments
    parser.add_argument('--data_root', type=str, default='processed_data/', help='Data root directory')
    parser.add_argument('--train_start_date', type=str, default='2024-06-06', help='Training start date')
    parser.add_argument('--train_end_date', type=str, default='2025-03-06', help='Training end date')
    parser.add_argument('--window_size', type=int, default=30, help='Observation window size')
    
    # Other arguments
    parser.add_argument('--use_wandb', action='store_true', help='Use Weights & Biases logging')
    parser.add_argument('--seed', type=int, default=42, help='Random seed')
    parser.add_argument('--model_dir', type=str, default='models', help='Model save directory')
    parser.add_argument('--list_combinations', action='store_true', help='List available feature combinations')
    
    args = parser.parse_args()
    
    # List available combinations if requested
    if args.list_combinations:
        feature_selector = FeatureSelector()
        feature_selector.print_available_combinations()
        return
    
    # Create training configuration
    config = {
        # Environment settings
        'seed': args.seed,
        'data_root': args.data_root,
        'stocks': None,  # Will be loaded from stocks.txt
        'train_start_date': args.train_start_date,
        'train_end_date': args.train_end_date,
        'window_size': args.window_size,
        'transaction_cost_rate': 0.005,
        'sharpe_window': 252,
        
        # Data loading settings
        'use_all_features': False,  # We'll use custom feature selection
        'fill_missing_features_with': 'interpolate',
        'save_cache': True,
        'cache_format': 'hdf5',
        'force_reload': False,
        'preload_to_gpu': True,
        
        # Training environment
        'n_envs': args.n_envs,
        'n_steps': args.n_steps,
        
        # PPO hyperparameters
        'num_updates': args.num_updates,
        'gamma': 0.99,
        'gae_lambda': 0.95,
        'clip_eps': 0.2,
        'ppo_epochs': args.ppo_epochs,
        'ppo_batch_size': args.ppo_batch_size,
        'learning_rate': args.learning_rate,
        'max_grad_norm': 1.0,
        'value_coeff': 0.5,
        'entropy_coeff': 0.02,
        'action_std': 0.5,
        
        # Network architecture
        'hidden_size': args.hidden_size,
        'n_lstm_layers': args.n_lstm_layers,
        
        # GPU optimizations
        'use_mixed_precision': True,
        'compile_mode': 'default',
        'memory_efficient': True,
        'gradient_checkpointing': True,
        
        # Logging and monitoring
        'use_wandb': args.use_wandb,
        'log_interval': 20,
        'save_interval': 100,
        'model_dir': args.model_dir,
    }
    
    # Run training
    try:
        run_training_with_combination(args.feature_combination, config)
        
    except KeyboardInterrupt:
        logger.info("Training interrupted by user")
        
    except Exception as e:
        logger.error(f"Training failed with error: {e}")
        raise


if __name__ == "__main__":
    main()
